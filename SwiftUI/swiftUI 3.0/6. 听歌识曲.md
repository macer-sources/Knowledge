1. 开启服务 
 apple developer 开启 app services 中的 `ShazamKit`服务 
2. 主体 实现 
```swift 

import Foundation
import ShazamKit
import AVKit
import SwiftUI

class ShazamRecognizer: NSObject, ObservableObject {
    
    @Published var session = SHSession()
    
    @Published var audioEngine = AVAudioEngine()
    
    @Published var errorMsg: String = ""
    @Published var showError: Bool = false
    
    @Published var isRecording = false
    
    override init() {
        super.init()
        session.delegate = self
    }
}

extension ShazamRecognizer: SHSessionDelegate {
    func session(_ session: SHSession, didFind match: SHMatch) {
        if let firstItem = match.mediaItems.first {
            debugPrint("\(firstItem)")
        }
    }
    func session(_ session: SHSession, didNotFindMatchFor signature: SHSignature, error: Error?) {
        DispatchQueue.main.async {
            self.errorMsg = error?.localizedDescription ?? ""
            self.showError.toggle()
            // stoping audio recording....
            self.stopRecording()
        }
    }
}


extension ShazamRecognizer {
    func listenMusic() {
        let audioSession  = AVAudioSession.sharedInstance()
        
        // checking for permission
        audioSession.requestRecordPermission { status in
            if status {
                self.recordAudio()
            }else {
                self.errorMsg = "Please Allow Microphone Access"
                self.showError.toggle()
            }
        }
    }
    
    func recordAudio() {
        if audioEngine.isRunning {
            stopRecording()
            return
        }
        // recording audio ...
        // first create a node ...
        // then listion to it ....
        let inputNode = audioEngine.inputNode
        let format = inputNode.outputFormat(forBus: .zero)
        
        inputNode.removeTap(onBus: .zero)
        
        
        inputNode.installTap(onBus: .zero, bufferSize: 1024, format: format) { buffer, time in
            // listen audio data
            // to
            self.session.matchStreamingBuffer(buffer, at: time)
        }
        
        audioEngine.prepare()
        
        do {
            try audioEngine.start()
            withAnimation {
                self.isRecording = true;
            }
        } catch  {
            self.errorMsg = error.localizedDescription
            self.showError.toggle()
        }
        
    }
    
    
    
    func stopRecording() {
        audioEngine.stop()
        withAnimation {
            isRecording = false
        }
    }
    
}



```


